#+SETUPFILE: ../theme-rose.setup
#+DATE: <2021-02-04 Thu 16:54>
#+TITLE: 当然我在扯淡（二）

** 程序语言的常见设计错误(1) - 片面追求短小

我经常以自己写“非常短小”的代码为豪。

我的程序的“短小”是建立在语义明确，概念清晰的基础上的。在此基础上，我力求去掉冗余的，绕弯子的，混淆的代码，让程序更加直接，更加高效的表达我心中设想的“模型”。这是一种在概念级别的优化，而程序的短小精悍只是它的一种“表象”。就像是整理一团电线，并不是把它们揉成一团然后塞进一个盒子里就好。这样的做法只会给你以后的工作带来更大的麻烦，而且还有安全隐患。

所以我的这种短小往往是语义和逻辑层面的，而不是在语法上死抠几行代码。我绝不会为了程序显得短小而让它变得难以理解或者容易出错。相反，很多其他人所追求的短小，却是盲目的而没有原则的。在很多时候这些小伎俩都只是在语法层面上，比如想办法把两行代码“搓”成一行。可以说，这种“片面追求短小”的错误倾向，造就了一批语言设计上的错误，以及一批“擅长于”使用这些错误的程序员。

现在我举几个简单的“片面追求短小”的语言设计。

*** 自增减操作

很多语言里都有 i++ 和 ++i 这两个“自增”操作和 i-- 和 --i 这两个“自减”操作（下文合称“自增减操作”。很多人喜欢在代码里使用自增减操作，因为这样可以“节省一行代码”。殊不知，节省掉的那区区几行代码比起由此带来的混淆和错误，其实是九牛之一毛。）

从理论上讲，自增减操作本身就是错误的设计。因为它们把对变量的“读”和“写”两种根本不同的操作，毫无原则的合并在一起。这种对读写操作的混淆不清，带来了非常难以发现的错误。相反，一种等价的，“笨”一点的写法， =i=1+1= ，不但容易理解，而且在逻辑上更加清晰。

有些人很在乎 =i++= 与 =++i= 的区别，去追究 =(i++) + (++i)= 这类表达式的含义，追究 =i++= 与 =++i= 谁的效率更高。这些其实都是徒劳的。比如， =i++= 与 =++i= 的效率差别，其实来自于早期 C 编译器的愚蠢。因为 =i++= 需要在增加这后返回 =i= 原来的值，所以它其实被编译为：

#+BEGIN_EXAMPLE
(tmp = i, i = i + 1, tmp)
#+END_EXAMPLE

但是在

#+BEGIN_EXAMPLE
for (int i = 0; i < max; i++)
#+END_EXAMPLE

这样的语句中，其实你并不需要在 =i++= 之后得到它自增前的值。

#+BEGIN_EXPORT html
<essay>
原来，是这个意思，原来是这样……
</essay>
#+END_EXPORT

所以有人说，在这里应该用 =++i= 而不是 =i++= ，否则你就会浪费一次对中间变量 =tmp= 的赋值。而其实呢，一个良好设计的编译器应该在两种情况下都生成相同的代码。这是因为在 =i++= 的情况，代码其实先被转化为：

#+BEGIN_EXAMPLE
for (int i = 0; i < max; (tmp = i, i = i + 1, tmp))
#+END_EXAMPLE

由于 =tmp= 这个临时变量从来没用过，所以它会被编译器的 “dead code elimination” 消去。所以编译器最后实际上得到了：

#+BEGIN_EXAMPLE
for (int i = 0; i < max; i = i + 1)
#+END_EXAMPLE

所以，“精通”这些细微的问题，并不能让你成为一个好和程序员。很多人所认为的高明的技巧，经常都是因为早期系统设计的缺陷所致。一旦这些系统被改进，这些技巧没什么用处了。

真正正确的做法其实是：完全不使用自增操作，因为它们本来就是错误的设计。

*** 赋值语句返回值

在几乎所有像 C，C++，Java 的语言里， *赋值语句都可以被作为值* 。之所以设计成这样，是因为你就可以写这样的代码：

#+BEGIN_EXAMPLE
if (y = 0) { ... }
#+END_EXAMPLE

而不是

#+BEGIN_EXAMPLE
y = 0;
if (y) { ... }
#+END_EXAMPLE

程序好像缩短了一行，然而，这种写法经常引起一种常见的错误，那就是为了写 ~if (y == 0) { ... }~ 而把 ~==~ 比较操作符少打了一个 ~=~ ，变成了 ~if (y = 0) { ... }~ 。很多人犯这个错误，是因为数学里的 ~=~ 就是比较两个值是否相等的意思。

正确的做法是什么呢？在一个类型完备的语言里面，像 ~y=0~ 这样的赋值语句，其实是不应该可以返回一个值的，所以它不允许你写：

#+BEGIN_EXAMPLE
x = y = 0
#+END_EXAMPLE

或者

#+BEGIN_EXAMPLE
if ( y = 0) { ... }
#+END_EXAMPLE

这样的代码。

~x = y = 0~ 的工作原理其实是这样：经过 parser 它其实变成了 ~x = (y = 0)~ （因为 ~=~ 操作符是“右结合”的）。 ~x = (y = 0)~ 这个表达式也就是说 =x= 被赋值为 =(y = 0)= 的值。注意，我说的是 =(y = 0)= 这整个表达式的值，而不是 =y= 的值。所以这里的 =(y = 0)= 既有副作用又是值，它返回 =y= 的“新值”。

正确的做法其实是： =y = 0= 不应该具有一个值。它的作用应该是“赋值”这种“动作”，而不应该具有任何“值”。即使牵强一点硬说它有值，它的值也应该是 =void= 。这样一来 ~x = y = 0~ 和 ~if (y = 0)~ 就会因为“类型不匹配”而被编译器拒绝接受，从而避免了可能出现的错误。

#+BEGIN_EXPORT html
<essay>
从源头解决问题的出现，而不只为了解决出现的问题。
</essay>
#+END_EXPORT

** “解决问题”与“消灭问题”

一直以来，人们都重视“解决问题”的能力，却忽视了另一种重要的能力：“消灭问题”的能力。

如果你仔细观察就会发现，很多“难题”，其实是“人造”出来的，而不是“必然”的。它们的存在，往往是由于一些早期的“设计错误”。人造的东西里面往往有设计上的错误，如果你把这些东西看成是不可改变的东西，那你就会遇到很多不必要的问题。

我经常发现计算机科学界存在这样的问题。研究了几十年，结果到最后才发现，辛辛苦苦解决的问题，其实包含了错误的假设。如果换一个角度来看，或者稍微改一改设计，这问题就基本不存在了。其中一个例子，就是编译器里面的“语法分析”（parsing）问题。

语法分析成为一个问题的原因，就在于很多人错误地以为程序语言应该有复杂的语法。正是这些复杂的语法，造成了这个问题研究了很多年，仍然没有一个很好的解决方案。可是一旦语法设计被简化（比如像 Lisp 那样），语法分析就变成一个非常容易的问题。实际上计算机系统（比如 Unix ）里的很多问题都是由此引发的，想要利用字符串来进行数据交换，却又设计了一些非常不方便的“数据格式”。简单的语法设计，会让这些问题一并消失掉。

爱因斯坦说“想象力比知识更重要”，也许就是这个道理。没有想象力的人经常钻牛角尖，走死胡同，忘记了自己其实还有另外的路可走。

#+BEGIN_EXPORT html
<essay>
道可道，非常道…… 故常无，欲以观其妙；常有，欲以观其徼。想象力就是有无转换的鹊桥。
</essay>
#+END_EXPORT

** 论对东西的崇拜

……

** Lisp 已死，Lisp 万岁！

首先，我想总结一下 Lisp 的优点。

- Lisp 的语法是世界上最精炼，最美观，也是语法分析起来最高效的语法；
- Lisp 是第一个可以在程序的任何位置定义函数，并且可以把函数作为值传递的语言；
- Lisp 有世界上最强大的宏系统（macro system）。这种宏系统的表达力几乎达到了理论所允许的极限；
- Lisp 是世界上第一个使用垃圾回收（garbage collection）的语言。

想不到吧，现代语言的很多优点，其实都是来自于 Lisp -- 世界上第二古老的程序语言。所以有人才说，每一种现代语言都在朝着 Lisp 的方向“进化”。

为什么 Lisp 今天没有成为主流，为什么 Lisp Machine 会被 Unix 打败？其实除了商业原因之外，还有技术上的问题。

早期的 Lisp 其实普遍存在一个非常严重的问题：它使用 =dynamic scoping= 。所谓 =dynamic scoping= 就是说，如果你的函数定义里面有“自由变量”，那么这个自由变量的值，会随着函数的“调用位置”的不同而发生变化。

#+BEGIN_EXPORT html
<essay>
竟然在这里解决了这个疑惑……
</essay>
#+END_EXPORT

比如下面我定义一个函数 =f= ，它接受一个参数 =y= ，然后返回 =x= 和 =y= 的积。

#+BEGIN_SRC lisp -n
  (setq f
        (let ((x 1))
          (lambda (y) (* x y))))
#+END_SRC

这里的 =x= 对于函数 =(lambda (y) (* x y))= 来说就是个“自由变量”（free variable），因为它不是它的参数。

看着这段代码，你会很自然的认为，因为 =x= 的值是 =1= ，那么 =f= 被调用的时候，结果应该等于 =(* 1 y)= ，也就是说应该等于 =y= 的值。可以这在 =dynamic scoping= 的语言结果如何呢？我们来看看吧。

如果我们在函数调用的外层定义一个 =x= ，值为 =2= ：

#+BEGIN_SRC lisp -n
  (let ((x 2))
    (funcall f 2))                        ; → 4
#+END_SRC

因为这个 =x= 跟 =f= 定义处的 =x= 的作用域不同，所以它们不应该互相干扰。所以我们应该得到 =2= ，可是，这段代码返回的结果却为 =4= 。

再来。我们另外定义一个 =x= ，值为 =3= ：

#+BEGIN_SRC lisp -n
  (let ((x 3))
    (funcall f 2))                        ; → 6
#+END_SRC

我们的期望值还是 =2= ，可是结果却是 =6= 。

再来。如果，我们直接调用：

#+BEGIN_SRC lisp -n
  (funcall f 2)
#+END_SRC

你想这次总该得到 =2= 了吧？结果，出错了：

#+BEGIN_EXAMPLE
Debugger entered--Lisp error: (void-variable x)
  (* x y)
  (lambda (y) (* x y))(2)
  funcall((lambda (y) (* x y)) 2)
  eval_r((funcall f 2) nil)
  eval-last-sexp-1(nil)
  eval-last-sexp(nil)
  call-interactively(eval-last-sexp nil nil)
#+END_EXAMPLE

看到问题了吗？ =f= 的行为，随着调用位置的一个“名叫 x” 的变量的值而发生变化。而这个 =x= ，跟 =f= 定义处的 =x= 其实根本就不是同一个变量，它们只不过名字相同而已。这会导致非常难以发现的错误，也就是早期 Lisp 最令人头痛的地方。好在现在的大部分语言其实已经吸取了这个教训，所以你不再会遇到这种让人发疯的痛苦。

如果我告诉你，Lisp Machine 所使用的语言 Lisp Machine Lisp 使用的也是 =dynamic scoping= ，你也许就明白为什么 Lisp Machine 会失败了。

话说回来，为什么早期的 Lisp 会使用 =dynamic scoping= 呢？其实这根本就不是一个有意的“设计”，而一个无意的“巧合”。你几乎什么都不用做，它就成了这个样子了。这不是开玩笑的，如果你在 emacs 里面显示 =f= 的值，它会打印出：

#+BEGIN_EXAMPLE
  '(lambda (y) (* x y))
#+END_EXAMPLE

这说明 =f= 的值其实是一个S表达式，而不是像 Scheme 一样的“闭包”（closure）。原来，Emacs Lisp 直接把函数定义处的S表达式 ='(lambda (y) (* x y))= 作为了函数的“值”，这是一种很幼稚的做法。

简单倒是简单，麻烦事接着就来了。调用 =f= 的时候，比如 =(funcall f 2)= ， =y= 的值当然来自参数 =2= ，可以 =x= 的值是多少呢？答案是：不知道！不知道怎么办？到“外层环境”去找呗，看到哪个就用哪个，看不到就报错。

那么正确的实现函数的做法是什么呢？是制造“闭包”。这也就是 Scheme，Common Lisp 以及 Python，C# 的做法。在函数定义被解释或者编译的时候，当时的自由变量（比如 =x= ）的值，会跟函数的代码绑在一起，被放进一种叫做“闭包”的结构里。比如上面的函数，就可以表示成这个样子：

#+BEGIN_EXAMPLE
(Closure '(lambda (y) (* x y)) '((x . 1)))
#+END_EXAMPLE

#+BEGIN_EXPORT html
<essay>
自由变量，就是在函数中被使用，但是不做为形参的变量。
</essay>
#+END_EXPORT

在这里我用 =（Closure ...）= 表示一个“结构”（就像 C 语言的 =struct= ）。它的第一个部分，是这个函数的定义。第二个部分是 ='((x . 1))= ，它是一个“环境”，其实就是一个从变量到时值的映射（ =map= ）。利用这个映射，我们记住函数定义处的那个 =x= 的值，而不是在调用的时候才去瞎找。

与 =dynamic scoping= 相对的就是 =lexical scoping= 。我刚才告诉你的闭包，就是 =lexical scoping= 的实现方法。

你也许发现了，Lisp 其实不是一种语言，而是很多种语言 。这些被人叫做“Lisp 家族”的语言，其实共同点只是它们的“语法”：它们都是基于 S表达式。如果你因此赞美的话，那么你赞美的其实只是 S表达式，而不是语言本身。 *因为一个语言的本质应该是由它的语义决定的，而跟语法没有很大关系。* 你甚至可以给同一种语言设计多种不同的语法，而不改变这种语言的本质。

其实老 Lisp 的死去还有另外一个重要的原因，那就是因为早期的 Lisp 编译器生成的代码效率非常低下。

** Chez Scheme 的传说

编译器是一种神秘，有趣，又无聊的程序。说它神秘，是因为只有非常少的人知道如何写出优秀的编译器。说它有趣，是因为编译器的技术里面信有大量的“哲学问题”和深刻的理论（比如 partial evaluation）。但为什么又说它无聊呢？因为你一旦掌握了编译器技术里面最精华的原理，就会发现其实说来说去就那么点东西。编译器代码里面的“创造性含量”其实非常低。里面有些固定的“模式”，几十年都不变。这是因为编译器只是一种“工具”，而不是最终的“目的”。设计应用程序才是程序员的最终目的。只有应用程序才能有无穷无尽的创造性。然而，我并不是说变通程序员不应该学习写编译器。相反，编译器的原理是非常重要的知识。

先来说一说为什么早期的 Lisp 编译器生成的代码效率低下吧。在函数式语言的早期，由于它比普通的语言多了一些表达式强大的构造（比如函数作为值的传递），人们其实都不知道如何实现它的编译器。很多 Scheme 的编译器其实只是把 Scheme 编译成 C ，然后再调用 C 语言的编译器。

在我看来，早期 Lisp 编译器出现的主要问题，其实在于对编译的本质的理解，以及编译器与解释器的根本区别。解释器之所以大部分时候比编译器慢，是因为解释器“问太多的问题”。每当看到一个构造，解释器就会问：“这是一个整数吗？”“这是一个字符串吗？”“这是一个函数吗？”…… 然后根据问题的结果进行不同的处理。这些问题，在编译器的理论里面叫做“解释开销”（interpretive overhead）。 *编译的本质，其实就是在程序运行之前进行“静态分析”* ，试图一劳永逸的回答这些问题。于是编译后的代码根本不问这种问题，它直接就知道那个位置肯定会出现什么构造，应该做什么事，于是它就直接去做了。早期的 Lisp 编译器，以及现在的很多 Scheme 编译器出现的问题其实在于，它们并没有干净的消除这些问题，甚至根本没有消除这些问题。

第一次遇到 Kent 的时候，他安静的对我说，你应该拥有自己的代码，将来有一天，你会发现它的价值。

Chez Scheme 从头到尾都是 Kent（R. Kent Dybving）一个人作品。它的工作原理是从 Scheme 源程序一直编译到机器代码，而不依赖任何其他语言的编译器。它甚至不依赖第三方的汇编器，所有三种体系构架（Intel，ARM，SPARC）的汇编器，都是 Kent 自己写的。

#+BEGIN_EXPORT html
<essay>
这…… 真的是牛！！！
</essay>
#+END_EXPORT

在这些先进的优化技术下，几乎所有的冗余代码都会被编译器消除掉。

** 什么是“脚本语言”

其实“脚本语言”与“非脚本语言”并没有语义上，或者执行方式上的区别。它们的区别只在于它们设计的初衷：脚本语言的设计，往往是作为一种临时的“补丁”。它的设计者并没有考虑把它作为一种“通用程序语言”，没有考虑用它构建大型的软件。这些设计者往往没有经过系统的训练，有些甚至连最基本的程序语言概念都没搞清楚。相反。“非脚本”的通用程序语言，往往由经过严格训练的专家甚至一个小组的专家设计，它们从一开头就考虑到了“通用性”，以及在大型工程中可靠性和可扩展性。

首先我们来看看“脚本”这个概念是如何产生的。使用 Unix 系统的人都会敲入一些命令，而命令貌似都是“一次性”或者“可抛弃”的。然而不久，人们就发现这些命令其实并不是那么的“一次性”，自己其实一直在重复的敲入类似的命令，所以有人就发明了“脚本”这东西。它的设计初衷是“批量式”的执行命令，你在一个文件里把命令都写进去，然后执行这个文件。可是不久人们就发现，这些命令行其实可以用更加聪明的方法构造，比如定义一些变量，或者根据系统类型的不同执行不同的命令。于是，人们为这脚本语言加入变量，条件语句，数组等等构造。“脚本语言”就这样产生了。

然而人们却没有发现，其实他们根本就不需要脚本语言。因为脚本语言里面的这些结构，在任何一种“严肃”的程序语言（比如 Java，Scheme）里面，早就已经存在了，而且设计得更加完善。所以脚本语言往往是在重新发明轮子，甚至连轮子都设计不好。早期脚本语言的“优势”，也许只在于它不需要事先“编译”，它“调用程序”的时候，貌似可以少打几个字。脚本语言对于 C 宋的语言，也放有一定的价值。然而，如果跟 Scheme 或者 Java 这样的语言来比，这个优势就非常不明显了。比如，你完全可以想一个自动的办法，写了 Java 代码之后，先调用 Java 编译器，然后调用 JVM，最后删掉 class 文件。或者你可以选择一种有解释执行方式的“严肃语言”，比如 Scheme 。

很多人把 Scheme 误称为“脚本语言”，就是因为它像脚本语言一样可以解释执行，然而 Scheme 其实是比 C 和 Java 还要“严肃”的语言。Scheme 从一开头就被设计为一种“通用程序语言”，而不是用来进行某种单一简单的任务。Scheme 的设计者比 Java 的设计者造诣更加深厚，所以全心全意对 Java 的一些设计错误看得非常清楚。像 Chez Scheme 这样的编译器，其实早就可以把 Scheme 解释器也会进行一定程序的“编译”，有些编译为字节码，有些编译为机器代码，然后再执行。所以在这种情况下，通常人们所谓的“编译性语言”与“解释性语言”，几乎没有本质上的区别，因为你看到的“解释器”，不过是自动的先编译再执行。

跟 Java 或者 Scheme 这样的语言截然不同，“脚本语言”往往意味着异常拙劣的设计，它的设计初衷往往是目光短浅的。这些语言里面充满了历史遗留下来的各种临时的 hack，几乎没有“原则”可言。

所以我认为脚本语言是一个祸害，它几乎永远是错误的决定。我们应该尽一切可能避免使用脚本语言。在没有办法的情况下，也应该在脚本里面尽可能的使用通常的程序设计原则。

** 函数式语言的宗教

很早的时候，“函数式语言”对于我来说就是 Lisp ，因为 Lisp 可以在程序的几乎任意位置定义函数，并且把它们作为值来传递（这电做 first-class function）。可是后来有人告诉我，Lisp 其实不算“函数式语言”，因为 Lisp 的函数不“纯”（pure）。

所谓“纯函数”，就是像数学函数一样，你给它同样的输入，它就给你同样的输出。

……

说了这么多，对于“函数式语言”这一概念的误解，应该消除得差不多了。其实“函数式语言”唯一的要求，应该是能够在任意位置定义函数，并且能够把函数作为值传递，不管这函数是“纯”的还是“不纯”的。

** 惰性求值

……

** Currying 的局限性

……

** 爱因斯坦谈教育

#+BEGIN_QUOTE
教育的唯一理性的方式是自己做一个榜样——如果实在不行，你可以做一个反例。

教育应该是这样：被传授的知识应该被当成宝贵的礼物，而不是沉重的任务。
#+END_QUOTE

